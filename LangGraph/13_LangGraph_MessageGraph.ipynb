{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Reducer\n",
    "- Reducer는 LangGraph에서 상태 업데이트를 관리하는 중요한 개념\n",
    "- 그래프의 각 노드의 출력을 그래프의 상태에 통합하는 방법을 정의\n",
    "- Reducer의 필요성\n",
    "    - 상태 덮어쓰기 문제: 기본적으로 각 노드의 반환값은 해당 상태 키의 이전 값을 덮어쓰는 방식으로 동작 (override)\n",
    "    - 누적 업데이트 필요: 특히 메시지 리스트와 같은 경우, 이전 상태에 새로운 값을 추가하고 싶을 때가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Reducer를 별도로 지정하지 않은 경우 `\n",
    "- reducer를 별도로 지정하지 않은 경우 기존 값을 덮어쓰는 방식으로 동작\n",
    "- 기본 reducer는 상태에 대해 별도의 설정 없이 사용될 때 자동으로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 상태 정의 \n",
    "class DocumentState(TypedDict):\n",
    "    query: str\n",
    "    documents: List[str]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc3.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(DocumentState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Reducer를 별도로 지정하는 경우 `\n",
    "- `Annotated` 사용하여 지정한 reducer 작동 방식에 따라 기존 상태 정보를 업데이트 \n",
    "- 리스트를 병합하는 `operator.add`를 사용하면, activity_log를 누적하는 방식으로 노드를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "class ReducerState(TypedDict):\n",
    "    query: str\n",
    "    #documents: List[str]\n",
    "    documents: Annotated[List[str], add]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Custom Reducer 사용 `\n",
    "- 상태 업데이트가 기본적인 덮어쓰기나 병합만으로 해결되지 않을 때 유용한 방법\n",
    "- 중복 제거, 최대/최소 값 유지, 조건부 병합 등의 특정 비즈니스 로직이 필요한 경우에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "\n",
    "# Custom reducer: 중복된 문서를 제거하며 리스트 병합\n",
    "def reduce_unique_documents(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Combine two lists of documents, removing duplicates.\"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    # 중복 제거: set을 사용하여 중복된 문서를 제거하고 다시 list로 변환\n",
    "    return list(set(left + right))\n",
    "\n",
    "# 상태 정의 (documents 필드 포함)\n",
    "class CustomReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], reduce_unique_documents]  # Custom Reducer 적용\n",
    "\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(CustomReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\", \"documents\": []}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MessageGraph\n",
    "- LangChain의 ChatModel은 Message 객체 목록을 입력으로 처리 (StateGraph의 특수한 유형)\n",
    "- 이러한 메시지들은 HumanMessage(사용자 입력)나 AIMessage(LLM 응답) 등 다양한 형태로 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Messages State 정의`\n",
    "- 이전 대화 기록을 그래프 상태에 메시지 목록으로 저장하는 것이 유용\n",
    "- 그래프 상태에 Message 객체 목록을 저장하는 키(채널)를 추가하고, 이 키에 리듀서 함수를 추가 \n",
    "- 리듀서 함수 선택:\n",
    "    - operator.add를 사용하면: 새 메시지를 기존 목록에 단순히 추가\n",
    "    - add_messages 함수를 사용하면:\n",
    "        - 새 메시지는 기존 목록에 추가\n",
    "        - 기존 메시지 업데이트도 올바르게 처리 (메시지 ID를 추적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 기본 State 초기화 방법을 사용\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph MessagesState라는 미리 만들어진 상태를 사용\n",
    "from langgraph.graph import MessagesState\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "'''\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "'''\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    # messages 키는 기본 제공 - 다른 키를 추가하고 싶을 경우 아래 주석과 같이 적용 가능 \n",
    "    documents: List[Document]\n",
    "    grade: float\n",
    "    num_generation: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) RAG Chain 구성`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)\n",
    "- LangChain Runnable로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "채식주의자를 위한 메뉴는 가든 샐러드와 버섯 크림 수프가 있습니다. 두 메뉴 모두 고기를 포함하지 않아 채식주의자에게 적합합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\") \n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"./db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# RAG 체인 구성\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "system = \"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the user's question:\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 검색기 정의\n",
    "retriever = menu_db.as_retriever(\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# RAG 체인 실행\n",
    "query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# 답변 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 노드(Node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "}\n",
    "'''\n",
    "# RAG 수행 함수 정의\n",
    "def retrieve_and_respond(state: GraphState):\n",
    "    \"\"\"\n",
    "    주어진 상태에서 질문을 추출하고 RAG(Retrieval-Augmented Generation)를 수행하는 함수\n",
    "    \n",
    "    Args:\n",
    "        state (GraphState): 현재 그래프 상태 객체. 다음을 포함:\n",
    "            - messages: 대화 메시지 리스트 (마지막 메시지는 사용자 질문)\n",
    "            \n",
    "    Returns:\n",
    "        dict: 업데이트된 상태 객체. 다음을 포함:\n",
    "            - messages: AI 응답 메시지가 추가된 메시지 리스트\n",
    "            - documents: 검색된 문서 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    # 상태에서 마지막 메시지 가져오기 (사용자의 질문)\n",
    "    # state['messages']는 대화 기록을 저장하는 리스트\n",
    "    last_human_message = state['messages'][-1]\n",
    "    \n",
    "    # HumanMessage 객체에서 실제 질문 내용 추출\n",
    "    # HumanMessage는 langchain_core.messages에 정의된 사용자 메시지 클래스\n",
    "    query = last_human_message.content\n",
    "    \n",
    "    # 벡터 저장소에서 질문과 관련된 문서 검색\n",
    "    # retriever는 FAISS 벡터 저장소에서 similarity search를 수행하는 객체\n",
    "    # search_kwargs={\"k\": 6}로 설정되어 상위 6개 문서 반환\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    # RAG 체인을 사용하여 응답 생성\n",
    "    # rag_chain은 다음으로 구성된 체인:\n",
    "    # 1. 검색된 문서를 context로 변환\n",
    "    # 2. 사용자 질문과 결합\n",
    "    # 3. LLM 모델로 전달하여 응답 생성\n",
    "    # 4. 문자열 파싱\n",
    "    response = rag_chain.invoke(query)\n",
    "    \n",
    "    # 데이트된 상태 반환\n",
    "    return {\n",
    "        # 기존 메시지에 AI 응답 메시지 추가\n",
    "        # AIMessage는 langchain_core.messages에 정의된 AI 응답 메시지 클래스\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        # 검색된 문서 저장 (나중에 답변 평가에 사용)\n",
    "        # documents는 langchain_core.documents.Document 객체 리스트\n",
    "        \"documents\": retrieved_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradeResponse 모델: 점수(score)와 설명(explanation)을 구조화된 형태로 저장\n",
    "\n",
    "* score: 0~1 사이 값 (1이 최고점)\n",
    "\n",
    "* explanation: 점수에 대한 설명\n",
    "\n",
    "### 평가 프로세스:\n",
    "\n",
    "* 대화 기록에서 질문과 답변 추출\n",
    "\n",
    "* 참고 문서를 문자열로 변환\n",
    "\n",
    "* LLM에게 평가 요청 (질문, 문서, 답변 제공)\n",
    "\n",
    "* 결과를 구조화된 형식(GradeResponse)으로 수신\n",
    "\n",
    "### 오류 처리:\n",
    "\n",
    "* 평가 실패 시 기본 점수(0.5) 반환\n",
    "\n",
    "* 점수 범위 보정(0 미만 → 0, 1 초과 → 1)\n",
    "\n",
    "### 상태 업데이트:\n",
    "\n",
    "* grade: 평가 점수 저장\n",
    "\n",
    "* num_generation: 답변 생성 횟수 카운팅\n",
    "\n",
    "* 이 함수는 LangGraph에서 자동 재시도 로직과 연결되어 답변 품질이 낮을 경우 재생성을 트리거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 답변 평가 결과를 위한 데이터 모델 정의\n",
    "class GradeResponse(BaseModel):\n",
    "    \"A score for answers\"\n",
    "    # 점수 (0~1 사이 값, 1이 최고점)\n",
    "    score: float = Field(\n",
    "        ...,  # 필수 항목\n",
    "        ge=0,  # 최소값 0\n",
    "        le=1,  # 최대값 1 \n",
    "        description=\"0에서 1 사이의 점수, 1은 완벽한 답변\"\n",
    "    )\n",
    "    # 평가 설명\n",
    "    explanation: str = Field(\n",
    "        ...,  # 필수 항목\n",
    "        description=\"주어진 점수에 대한 설명\"\n",
    "    )\n",
    "    \n",
    "# 답변 품질 평가 함수\n",
    "def grade_answer(state: GraphState):\n",
    "    \"\"\"\n",
    "    AI의 답변을 평가하여 점수를 매기는 함수\n",
    "    \n",
    "    Args:\n",
    "        state (GraphState): 현재 상태 객체\n",
    "            - messages: 대화 기록 (마지막 두 메시지: [질문, 답변])\n",
    "            - documents: 참고 문서\n",
    "            \n",
    "    Returns:\n",
    "        dict: 업데이트된 상태\n",
    "            - grade: 평가 점수 (0~1)\n",
    "            - num_generation: 답변 생성 횟수\n",
    "    \"\"\"\n",
    "    \n",
    "    # 대화 기록에서 질문과 답변 추출\n",
    "    messages = state['messages']\n",
    "    # 마지막에서 두번째 메시지(사용자 질문)\n",
    "    question = messages[-2].content\n",
    "    # 마지막 메시지(AI 답변)\n",
    "    answer = messages[-1].content\n",
    "    # 참고 문서를 문자열로 변환\n",
    "    context = format_docs(state['documents'])\n",
    "    \n",
    "    # 평가자 역할을 정의하는 시스템 프롬프트\n",
    "    grading_system = \"\"\"\n",
    "    당신은 전문 평가자입니다.\n",
    "    주어진 컨텍스트를 고려하여 답변의 정확성과 관련성을 평가하세요.\n",
    "    0에서 1 사이의 점수(1이 완벽)와 설명을 제공하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    # 평가를 위한 프롬프트 템플릿 생성\n",
    "    grading_prompt = ChatPromptTemplate.from_messages([\n",
    "        # 평가자 역할 설정\n",
    "        (\"system\", grading_system),\n",
    "        (\"human\", \n",
    "         \"[질문]\\n{question}\\n\\n\"    # 사용자 질문\n",
    "         \"[컨텍스트]\\n{context}\\n\\n\"  # 참고 문서\n",
    "         \"[답변]\\n{answer}\\n\\n\"       # AI 답변\n",
    "         \"[평가]\\n\")                  # 평가 요청\n",
    "        #(\"human\", \"[Question]\\n{question}\\n\\n[Context]\\n{context}\\n\\n[Answer]\\n{answer}\\n\\n[Grade]\\n\")\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # 평가 체인 구성: 프롬프트 → LLM → 구조화된 출력\n",
    "        grading_chain = grading_prompt | llm.with_structured_output(\n",
    "            schema=GradeResponse  # 출력 형식 지정\n",
    "        )\n",
    "        # 실제 평가 수행\n",
    "        grade_response = grading_chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "        \n",
    "        # 점수 범위 보정 (0~1 사이로 강제 조정)\n",
    "        score = max(0, min(1, grade_response.score))  # Clamp between 0 and 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 평가 실패 시 처리\n",
    "        print(f\"Error during grading: {e}\")\n",
    "        # 기본 점수\n",
    "        score = 0.5\n",
    "        grade_response = GradeResponse(\n",
    "            score=score, \n",
    "            explanation=\"평가 과정에서 오류가 발생했습니다\"\n",
    "        )\n",
    "\n",
    "    # 답변 생성 횟수 업데이트 (초기값 0)\n",
    "    num_generation = state.get('num_generation', 0)\n",
    "    # 횟수 증가\n",
    "    num_generation += 1\n",
    "    \n",
    "    return {\n",
    "        # 평가 점수\n",
    "        \"grade\": score, \n",
    "        # 생성 횟수\n",
    "        \"num_generation\": num_generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 엣지(Edge)`\n",
    "\n",
    "#### 함수 동작 설명:\n",
    "* 1.입력:\n",
    "    * state: 현재 시스템 상태 (평가 점수와 시도 횟수 포함)\n",
    "* 2. 로직:\n",
    "    * 먼저 시도 횟수를 확인 → 3회 이상이면 무조건 종료\n",
    "    * 점수가 0.7 미만이면 재생성 필요\n",
    "    * 0.7 이상이면 성공으로 간주\n",
    "*3. 출력:\n",
    "    * retrieve_and_respond: 답변 재생성 필요\n",
    "    * generate: 현재 상태 유지\n",
    "* 디버깅 정보:\n",
    "    * 콘솔에 현재 점수와 결정 사유 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def should_retry(state: GraphState) -> Literal[\"retrieve_and_respond\", \"generate\"]:\n",
    "    \"\"\"\n",
    "    현재 답변의 품질을 평가하여 재시도 여부를 결정하는 함수\n",
    "    \n",
    "    Args:\n",
    "        state (GraphState): 현재 상태 객체\n",
    "            - grade: 최근 답변의 평가 점수 (0~1)\n",
    "            - num_generation: 답변 생성 시도 횟수\n",
    "            \n",
    "    Returns:\n",
    "        \"retrieve_and_respond\" or \"generate\":\n",
    "            - \"retrieve_and_respond\": 답변 재생성 필요 (RAG 프로세스 다시 실행)\n",
    "            - \"generate\": 현재 답변으로 충분 (프로세스 종료)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 디버깅을 위한 평가 점수 출력\n",
    "    print(\"----평가 결과 확인----\")\n",
    "    print(\"현재 점수:\", state[\"grade\"])\n",
    "    print(\"생성 시도 횟수:\", state[\"num_generation\"])\n",
    "\n",
    "    # 1. 최대 시도 횟수 확인 (3회 이상이면 중단)\n",
    "    if state[\"num_generation\"] > 2:\n",
    "        print(\"※ 최대 시도 횟수(3회) 도달 - 프로세스 종료\")\n",
    "        return \"generate\"  # 더 이상 시도하지 않음\n",
    "    \n",
    "    # 2. 점수 평가 (0.7 미만이면 재시도)\n",
    "    if state[\"grade\"] < 0.7:\n",
    "        print(\"※ 점수 미달(0.7 미만) - 답변 재생성 필요\")\n",
    "        return \"retrieve_and_respond\"  # RAG 프로세스 재실행\n",
    "    else:\n",
    "        print(\"※ 충분한 점수(0.7 이상) - 프로세스 완료\")\n",
    "        return \"generate\"  # 현재 답변으로 만족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 그래프(Graph) 구성`\n",
    "\n",
    "### generate에 대한 추가 설명\n",
    "* 역할:\n",
    "    * 가상의 \"종료 신호\"로 작동\n",
    "    * END 노드의 별칭(alias)으로 사용됨\n",
    "    * 실제 함수가 아닌 흐름 제어 키워드\n",
    "* 설계 의도:\n",
    "    * \"end\"보다 의도가 명확한 네이밍\n",
    "    * \"더 이상 생성(generate)하지 않는다\"는 의미 포함\n",
    "    * 재시도 로직과 대비되는 개념으로 사용    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 설정\n",
    "# StateGraph 객체 생성 (상태 타입으로 GraphState 사용)\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 그래프에 노드(Node) 추가\n",
    "# 1. retrieve_and_respond: 사용자 질문 처리 및 답변 생성 노드\n",
    "builder.add_node(\"retrieve_and_respond\", retrieve_and_respond)\n",
    "# 2. grade_answer: 생성된 답변의 품질을 평가하는 노드\n",
    "builder.add_node(\"grade_answer\", grade_answer)\n",
    "\n",
    "# 그래프의 엣지(Edge) 설정\n",
    "# 시작(START) → retrieve_and_respond 노드로 연결\n",
    "builder.add_edge(START, \"retrieve_and_respond\")\n",
    "# retrieve_and_respond → grade_answer 노드로 연결\n",
    "builder.add_edge(\"retrieve_and_respond\", \"grade_answer\")\n",
    "\n",
    "# 조건부 엣지 설정 (핵심 로직)\n",
    "builder.add_conditional_edges(\n",
    "    \"grade_answer\", # 출발 노드\n",
    "    should_retry,   # 조건 판단 함수\n",
    "    {\n",
    "        # 조건에 따른 분기 설정\n",
    "        \"retrieve_and_respond\": \"retrieve_and_respond\",  # 재시도 필요 시\n",
    "        \"generate\": END   # 종료 조건 시 (END는 특수 노드)\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "[조건부 엣지 상세 설명]\n",
    "- should_retry() 함수가 \"retrieve_and_respond\" 반환 시:\n",
    "  → retrieve_and_respond 노드로 이동 (답변 재생성 시도)\n",
    "- \"generate\" 반환 시:\n",
    "  → END 노드로 이동 (프로세스 종료)\n",
    "- generate는 실제 함수가 아닌 LangGraph의 예약된 동작으로\n",
    "  \"현재 결과를 최종 출력으로 사용하고 종료\"를 의미\n",
    "\"\"\"\n",
    "\n",
    "# 그래프 컴파일 (실행 가능한 객체 생성)\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) Graph 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "#query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "query = \"해산물 메뉴를 추천해주세요.\"\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\\n\")\n",
    "pprint(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변만 출력\n",
    "pprint(final_state['messages'][-1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 예시 질문들\n",
    "example_questions = [\n",
    "    \"채식주의자를 위한 메뉴를 추천해주세요.\",\n",
    "    \"오늘의 스페셜 메뉴는 무엇인가요?\",\n",
    "    \"파스타에 어울리는 음료는 무엇인가요?\"\n",
    "]\n",
    "\n",
    "# 대답 함수 정의\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "\n",
    "        # 기존 채팅 기록에 사용자의 메시지를 추가 (최근 2개 대화만 사용)\n",
    "        initial_state = {\n",
    "            \"messages\": chat_history[-2:]+[HumanMessage(content=message)],  \n",
    "        }\n",
    "\n",
    "        # 메시지를 처리하고 최종 상태를 반환\n",
    "        final_state = graph.invoke(initial_state)\n",
    "        \n",
    "        # 최종 상태에서 필요한 부분 반환 (예: 추천 메뉴 등)\n",
    "        return final_state[\"messages\"][-1].content\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Gradio 앱 실행\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
