{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec296ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc24ee9",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83022c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "# 콤마로 구분된 리스트 출력 파서 초기화\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 출력 형식 지침 가져오기\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "prompt.partial_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 모델 설정\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 체인 생성\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI 관련 기술\"에 대한 체인 호출 실행\n",
    "result = chain.invoke({\"subject\": \"AI 관련 기술\"})\n",
    "\n",
    "# 쉼표로 구분된 리스트 출력\n",
    "print(\" AI 관련 기술 목록:\")\n",
    "print(result)\n",
    "\n",
    "# 결과 활용 예시: CSV 파일로 저장\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI 기술\"])  # 헤더 추가\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' 파일로 저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7274ee4",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON 출력 파서 초기화\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿을 설정합니다.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 과학 분야 전문가 AI입니다. 질문에 대해 체계적이고 간결한 답변을 JSON 형식으로 제공하세요.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON 출력 형식 지침을 프롬프트에 적용\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75923997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 모델 설정\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "# 프롬프트, 모델, 출력 파서를 연결하는 체인 생성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 질문 설정 (우주 탐사 관련 질문)\n",
    "question = \"최근 10년간 진행된 주요 우주 탐사 미션 3가지를 알려주세요. \\\n",
    "각 미션의 이름은 `mission_name`에, 목표는 `goal`에, 주관 기관은 `agency`에 담아 주세요.\"\n",
    "\n",
    "# 체인 실행 및 JSON 응답 받기\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON 데이터 출력\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec9f7e",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser 설정\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# 형식 지침 출력\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b30e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 모델 응답 받기\n",
    "try:\n",
    "    # **Name 열을 표시하십시오.**\n",
    "    print('Name 컬럼 출력')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **첫번째 행을 표시하십시오.**\n",
    "    print('첫번째 행 출력')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 응답 스키마 정의 {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser 설정\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6303bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성 (프롬프트 → 모델 → OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 실행 함수\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # 모델 호출\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # 모델이 반환한 JSON을 Pandas DataFrame으로 변환\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # 결과 출력\n",
    "        print(\"\\n🔹 Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1375a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [예제 1] 2024년 상반기 서울 아파트 평균 매매 가격 데이터 생성\n",
    "print('2024년 하반기 서울 아파트 평균 매매 가격 데이터 생성')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (구), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8349a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2024년 서울 지하철역별 유동 인구 데이터')\n",
    "# [예제 2] 2024년 서울 지하철역별 유동 인구 데이터\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    # print(df_seoul_subway.shape)\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('한국 5대 편의점 브랜드별 2024년 매출 및 점포 수')\n",
    "# [예제 3] 한국 5대 편의점 브랜드별 2024년 매출 및 점포 수\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30758d",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94102728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 구조를 정의하는 Pydantic 모델\n",
    "class MovieRecommendation(BaseModel):\n",
    "    movie_title: str = Field(description=\"추천 영화 제목\")\n",
    "    reason: str = Field(description=\"추천 이유\")\n",
    "    genre: List[str] = Field(description=\"영화 장르\")\n",
    "    estimated_rating: float = Field(description=\"10점 만점에서 예상 평점\")\n",
    "    \n",
    "# Pydantic 출력 파서 초기화\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "template = \"\"\"\n",
    "다음 사용자 요청에 따라 영화를 추천해주세요.\n",
    "요청: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 파서의 지시사항을 프롬프트에 주입\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 구성 및 실행\n",
    "query = \"1990년대 클래식한 느낌의 공포 영화 추천해줘\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"추천 영화: {output.movie_title}\")\n",
    "print(f\"추천 이유: {output.reason}\")\n",
    "print(f\"장르: {', '.join(output.genre)}\")\n",
    "print(f\"예상 평점: {output.estimated_rating}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dce39a",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4772c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# 출력 구조 정의 (평점, 장점, 단점, 요약)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"rating\", description=\"5점 만점에서 예상 평점\"),\n",
    "    ResponseSchema(name=\"pros\", description=\"리뷰에서 언급된 장점 3가지를 리스트로 출력\"),\n",
    "    ResponseSchema(name=\"cons\", description=\"리뷰에서 언급된 단점 3가지를 리스트로 출력\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"리뷰를 한 문장으로 요약\")\n",
    "]\n",
    "\n",
    "# 파서 초기화\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"출력 형식 지시사항:\")\n",
    "print(format_instructions)\n",
    "template = \"\"\"\n",
    "다음 제품 리뷰를 분석하세요. 리뷰 내용: {review}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 (temperature=0.5로 설정해 일관성 있는 출력)\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 테스트 리뷰 데이터\n",
    "review = \"\"\"\n",
    "이 스마트폰은 배터리 수명이 정말 좋아서 하루 종일 사용해도 충전이 필요 없었어요. \n",
    "카메라 화질도 선명하고, 특히 야간 모드가 훌륭합니다. \n",
    "다만 가격이 조금 비싸고, 무게가 200g이 넘어서 손이 피곤할 수 있어요.\n",
    "\"\"\"\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"review\": review})\n",
    "\n",
    "# 결과 출력 (Pretty Print)\n",
    "print(\"===== 분석 결과 =====\")\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b071b",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0abd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "# 출력 파서 초기화 (시간대 포함 가능)\n",
    "datetime_parser = DatetimeOutputParser()\n",
    "format_instructions = datetime_parser.get_format_instructions()\n",
    "\n",
    "print(\"날짜 출력 형식 지시사항:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "# 현재 날짜를 명시적으로 프롬프트에 주입\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "template = f\"\"\"\n",
    "현재 날짜: {current_date}\n",
    "다음 텍스트에서 날짜/시간 정보를 추출하세요. 상대적 표현(예: '다음 주 금요일')은 현재 날짜를 기준으로 계산합니다.\n",
    "텍스트: {{text}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 (temperature=0.1로 설정해 정확한 날짜 출력 강조)\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# 테스트 데이터 (다양한 날짜 형식 포함)\n",
    "texts = [\n",
    "    \"회의는 2025년 6월 15일 오후 2시에 예정되어 있습니다.\",\n",
    "    \"프로젝트 마감일은 다음 주 금요일입니다.\",\n",
    "    \"행사 시작: 7/25/2025 18:00 KST\",\n",
    "    \"3일 후에 시스템 점검이 진행됩니다.\"\n",
    "]\n",
    "\n",
    "# 체인 실행 및 결과 출력\n",
    "chain = prompt | model | datetime_parser\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"\\n원본 텍스트: {text}\")\n",
    "    output = chain.invoke({\"text\": text})\n",
    "    print(f\"추출된 날짜: {output.strftime('%Y-%m-%d %H:%M:%S %Z')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이벤트 추출용 프롬프트\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "event_template = \"\"\"\n",
    "현재 날짜: {current_date}\n",
    "다음 텍스트에서 모든 이벤트의 날짜/시간을 추출하세요. 각 이벤트는 이름과 날짜를 포함해야 합니다.\n",
    "각 이벤트는 현재 날짜를 기준으로 계산합니다.\n",
    "텍스트: {text}\n",
    "\n",
    "출력 형식:\n",
    "- 이벤트명: [이름]\n",
    "- 날짜: [YYYY-MM-DD HH:MM:SS]\n",
    "\"\"\"\n",
    "\n",
    "event_prompt = ChatPromptTemplate.from_template(event_template)\n",
    "event_chain = event_prompt | model\n",
    "\n",
    "# 예시 텍스트 (여러 이벤트 포함)\n",
    "event_text = \"\"\"\n",
    "12월 10일에 크리스마스 마켓이 열리고, 12월 24일에는 크리스마스 이브 파티가 있습니다.\n",
    "또한 1월 1일 00:00에 새해 카운트다운이 진행될 예정입니다.\n",
    "\"\"\"\n",
    "\n",
    "print(event_chain.invoke({\"current_date\":current_date, \"text\": event_text}).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e269b",
   "metadata": {},
   "source": [
    "### EnumOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "# 감정 클래스 정의 (Enum)\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"긍정\"\n",
    "    NEGATIVE = \"부정\"\n",
    "    NEUTRAL = \"중립\"\n",
    "\n",
    "# EnumOutputParser 초기화\n",
    "enumParser = EnumOutputParser(enum=Sentiment)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"감정 분류 출력 형식:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "template = \"\"\"\n",
    "당신은 텍스트 감정 분석 전문가입니다.\n",
    "다음 텍스트의 감정을 분석하고, 반드시 아래 세 가지 중 하나의 단어로만 답변하세요.\n",
    "\n",
    "텍스트: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "중요 규칙:\n",
    "1. 반드시 \"긍정\", \"부정\", \"중립\" 중 하나의 단어만 출력하세요\n",
    "2. 다른 설명이나 부가 설명을 추가하지 마세요\n",
    "3. 이모지나 특수문자도 포함하지 마세요\n",
    "4. 오직 하나의 단어만 출력하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0  # 일관성을 위해 0으로 설정\n",
    ")\n",
    "\n",
    "# OutputFixingParser로 안정성 향상\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=enumParser, llm=model)\n",
    "\n",
    "print(\"모델 및 파서 설정 완료\")\n",
    "\n",
    "# 테스트 텍스트\n",
    "texts = [\n",
    "    \"이 제품 정말 좋아요! 완전 만족스러워요.\",\n",
    "    \"서비스가 너무 느리고 불친절했습니다.\",\n",
    "    \"오늘은 비가 온다네요.\",\n",
    "    \"배송은 빠르지만 품질이 아쉽습니다.\",\n",
    "    \"최고의 경험이었습니다!\",\n",
    "    \"완전 실망했어요... 최악이에요\"\n",
    "]\n",
    "\n",
    "print(f\"테스트할 텍스트 {len(texts)}개 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안전한 감정 분석 함수 (에러 처리 포함)\n",
    "def safe_sentiment_analysis(text, use_fixing_parser=True):\n",
    "    \"\"\"안전한 감정 분석 함수 - 에러 처리 포함\"\"\"\n",
    "    try:\n",
    "        # 기본 체인 생성\n",
    "        chain = prompt | model | (fixing_parser if use_fixing_parser else enumParser)\n",
    "        \n",
    "        # 분석 실행\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result, None\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        return None, f\"파싱 오류: {str(e)[:100]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"일반 오류: {str(e)[:100]}...\"\n",
    "\n",
    "# 실제 감정 분석 실행 (API 키 필요)\n",
    "def run_sentiment_analysis():\n",
    "    \"\"\"실제 감정 분석 실행\"\"\"\n",
    "    print(\"=== 실제 감정 분석 결과 ===\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_count = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{i}. 텍스트: {text}\")\n",
    "        \n",
    "        # OutputFixingParser 사용\n",
    "        result, error = safe_sentiment_analysis(text, use_fixing_parser=True)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   감정: {result.value} \")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   오류: {error} \")\n",
    "            \n",
    "            # 기본 파서로 재시도\n",
    "            print(\"   기본 파서로 재시도...\")\n",
    "            result2, error2 = safe_sentiment_analysis(text, use_fixing_parser=False)\n",
    "            \n",
    "            if result2:\n",
    "                print(f\"   감정: {result2.value} (기본 파서 성공)\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"   재시도 실패: {error2} \")\n",
    "    \n",
    "    print(f\"\\n=== 결과 요약 ===\")\n",
    "    print(f\"성공: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "    print(f\"실패: {total_count-success_count}/{total_count}\")\n",
    "\n",
    "# 실제 분석 실행 (API 키가 있는 경우)\n",
    "try:\n",
    "    run_sentiment_analysis()\n",
    "except Exception as e:\n",
    "    print(\"API 키가 설정되지 않았거나 네트워크 오류:\")\n",
    "    print(\"실제 실행을 위해서는 OpenAI API 키를 설정하세요.\")\n",
    "    print(f\"오류 상세: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a46a2",
   "metadata": {},
   "source": [
    "### BooleanOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import BooleanOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Boolean 파서 초기화\n",
    "boolParser = BooleanOutputParser()\n",
    "\n",
    "# 수동으로 포맷 지시사항 정의 (LangChain 버전 이슈 회피)\n",
    "format_instructions = \"\"\"\n",
    "출력은 반드시 다음 중 하나여야 합니다:\n",
    "- `True`: 모든 조건 충족 시\n",
    "- `False`: 하나라도 조건 불충족 시\n",
    "\n",
    "예시:\n",
    "True  # 모든 조건 만족\n",
    "False # 조건 불만족\n",
    "\"\"\"\n",
    "\n",
    "# 승인/거부 결정 프롬프트 템플릿\n",
    "template = \"\"\"\n",
    "다음 대출 신청자를 평가하세요. 조건을 모두 충족하면 `True`, 아니면 `False`를 출력하세요.\n",
    "\n",
    "### 조건:\n",
    "1. 나이 >= {min_age}세\n",
    "2. 신용 점수 >= {min_credit_score}\n",
    "3. 월 수입 >= ${min_income}\n",
    "\n",
    "### 신청자 정보:\n",
    "{applicant_details}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chain = prompt | model | boolParser\n",
    "\n",
    "# 테스트 케이스\n",
    "test_cases = [\n",
    "    {\n",
    "        \"min_age\": 18,\n",
    "        \"min_credit_score\": 700,\n",
    "        \"min_income\": 3000,\n",
    "        \"applicant_details\": \"\"\"\n",
    "        - 이름: 김철수\n",
    "        - 나이: 25세\n",
    "        - 신용 점수: 750\n",
    "        - 월 수입: $3,500\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"min_age\": 18,\n",
    "        \"min_credit_score\": 700,\n",
    "        \"min_income\": 3000,\n",
    "        \"applicant_details\": \"\"\"\n",
    "        - 이름: 이영희\n",
    "        - 나이: 17세\n",
    "        - 신용 점수: 680\n",
    "        - 월 수입: $2,800\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 거부 사유 생성 프롬프트 (출력 형식 명시적으로 지정)\n",
    "reason_template = \"\"\"\n",
    "다음 대출 신청 거부 사유를 1문장으로 설명하세요. 반드시 다음 형식으로 답변해야 합니다:\n",
    "\n",
    "[거부 사유]: [사유 내용]\n",
    "\n",
    "### 신청자 정보:\n",
    "{applicant_details}\n",
    "\n",
    "### 조건:\n",
    "- 최소 나이: {min_age}세\n",
    "- 최소 신용 점수: {min_credit_score}\n",
    "- 최소 월 수입: ${min_income}\n",
    "\"\"\"\n",
    "reason_prompt = ChatPromptTemplate.from_template(reason_template)\n",
    "reason_chain = reason_prompt | model | StrOutputParser()\n",
    "\n",
    "# 체인 확장 (Boolean 파서와 분리)\n",
    "def get_decision_with_reason(input_dict):\n",
    "    # 1. 먼저 Boolean 결정\n",
    "    decision = chain.invoke(input_dict)\n",
    "    \n",
    "    # 2. 거부 시에만 사유 생성\n",
    "    if not decision:\n",
    "        try:\n",
    "            reason = reason_chain.invoke({\n",
    "                \"applicant_details\": input_dict[\"applicant_details\"],\n",
    "                \"min_age\": input_dict[\"min_age\"],\n",
    "                \"min_credit_score\": input_dict[\"min_credit_score\"],\n",
    "                \"min_income\": input_dict[\"min_income\"]\n",
    "            })\n",
    "            return decision, reason\n",
    "        except Exception as e:\n",
    "            return decision, f\"거부 사유 생성 실패: {str(e)}\"\n",
    "    return decision, \"모든 조건을 충족했습니다.\"\n",
    "\n",
    "# 테스트 (안전한 실행)\n",
    "try:\n",
    "    decision, reason = get_decision_with_reason(test_cases[1])\n",
    "    print(f\"\\n결과: {'승인' if decision else '거부'}\")\n",
    "    print(f\"사유: {reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
